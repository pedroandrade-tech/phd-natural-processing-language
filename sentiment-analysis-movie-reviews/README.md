# ğŸ¬ AnÃ¡lise de Sentimentos em AvaliaÃ§Ãµes de Produtos

Projeto de Processamento de Linguagem Natural (PLN) para classificaÃ§Ã£o de sentimentos em reviews de filmes utilizando diferentes tÃ©cnicas de Machine Learning e Deep Learning.

## ğŸ“‹ Objetivo

Implementar e comparar trÃªs abordagens para classificaÃ§Ã£o de sentimentos:
- **SVM + Bag of Words (BoW)**
- **SVM + Word2Vec Embeddings**
- **BERT (Fine-tuning)**

## ğŸ“Š Dataset

- **Fonte:** Reviews de filmes extraÃ­das do IMDB
- **Total de reviews:** 545
- **DivisÃ£o:** 80% treino | 20% teste
- **ClassificaÃ§Ã£o:** BinÃ¡ria (Negativo/Positivo)

| Classe | CritÃ©rio | Quantidade |
|--------|----------|------------|
| Negativo (0) | Notas 1-5 | 340 |
| Positivo (1) | Notas 6-10 | 205 |

## ğŸ› ï¸ Metodologia

### 1. SVM + Bag of Words
- VetorizaÃ§Ã£o com `CountVectorizer`
- N-gramas: unigramas e bigramas
- Kernel: Linear

### 2. SVM + Word2Vec
- Embeddings prÃ©-treinados: `word2vec-google-news-300`
- RepresentaÃ§Ã£o: MÃ©dia dos vetores das palavras
- Kernel: RBF com `class_weight='balanced'`

### 3. BERT
- Modelo: `bert-base-uncased`
- Fine-tuning: 3 Ã©pocas
- Max length: 256 tokens

## ğŸ“ˆ Resultados

### ComparaÃ§Ã£o Geral

| Modelo | AcurÃ¡cia | F1-Macro | F1-Weighted |
|--------|----------|----------|-------------|
| SVM + BoW | 66.97% | 0.63 | 0.66 |
| SVM + Word2Vec | **78.90%** | **0.78** | **0.79** |
| BERT | **78.90%** | **0.78** | **0.79** |

### MÃ©tricas por Classe

| Modelo | Negativo (P/R/F1) | Positivo (P/R/F1) |
|--------|-------------------|-------------------|
| SVM + BoW | 0.71 / 0.79 / 0.75 | 0.58 / 0.46 / 0.51 |
| SVM + Word2Vec | 0.87 / 0.78 / 0.82 | 0.69 / 0.80 / 0.74 |
| BERT | 0.89 / 0.75 / 0.82 | 0.67 / 0.85 / 0.75 |

### Matrizes de ConfusÃ£o

```
SVM + BoW:           SVM + Word2Vec:       BERT:
[[54 14]             [[53 15]              [[51 17]
 [22 19]]             [ 8 33]]              [ 6 35]]
```

## ğŸ’¡ ConclusÃµes

1. **Embeddings semÃ¢nticos superam BoW:** Word2Vec e BERT tiveram desempenho ~12 pontos percentuais superior ao Bag of Words.

2. **BERT vs Word2Vec:** Desempenho similar em acurÃ¡cia, porÃ©m BERT obteve melhor recall na classe Positivo (85% vs 80%).

3. **Balanceamento de classes:** O uso de `class_weight='balanced'` no SVM foi crucial para melhorar o recall da classe minoritÃ¡ria.

4. **Trade-off:** BERT requer mais recursos computacionais e tempo de treino, mas oferece melhor equilÃ­brio entre as classes.

## ğŸš€ Como Executar

### Requisitos
```bash
pip install pandas numpy scikit-learn gensim transformers torch matplotlib seaborn
```

### Executar o Notebook
1. Abra o notebook no Google Colab
2. FaÃ§a upload do arquivo `reviews_extraidas.csv`
3. Execute as cÃ©lulas sequencialmente

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ README.md
â”œâ”€â”€ analise_sentimentos.ipynb    # Notebook principal
â”œâ”€â”€ reviews_extraidas.csv        # Dataset
â””â”€â”€ results/
    â”œâ”€â”€ confusion_matrix_bow.png
    â”œâ”€â”€ confusion_matrix_word2vec.png
    â””â”€â”€ confusion_matrix_bert.png
```

## ğŸ”§ Tecnologias Utilizadas

- Python 3.10+
- Scikit-learn
- Gensim (Word2Vec)
- Transformers (BERT)
- PyTorch
- Pandas / NumPy
- Matplotlib / Seaborn

## ğŸ‘¤ Autor

[Pedro Fonseca de Andrade]

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.
