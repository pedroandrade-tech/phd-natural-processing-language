{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287375f0",
   "metadata": {},
   "source": [
    "# BERT Fine-Tuning\n",
    "\n",
    "Binary sentiment classification using `bert-base-uncased` fine-tuned with HuggingFace Trainer.\n",
    "\n",
    "Prerequisite: run `00_preprocessing.ipynb` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d77fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67248ee6",
   "metadata": {},
   "source": [
    "## Load data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9865894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reviews_extraidas.csv')\n",
    "df['label'] = (df['Y'] > 5).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['X'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0a7e3",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels.iloc[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = ReviewDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09153473",
   "metadata": {},
   "source": [
    "## Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds, average='weighted'),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d7cda",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(-1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 (macro): {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"F1 (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Confusion Matrix \u2014 BERT')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce700aba",
   "metadata": {},
   "source": [
    "## Inference on new reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n    \"This movie was absolutely amazing! I loved every moment of it.\",\n    \"Terrible film. Waste of time and money. Do not watch.\",\n    \"It was okay, nothing special but not bad either.\",\n]\n\nlabel_map = {0: 'Negative', 1: 'Positive'}\nmodel_cpu = model.cpu()\nmodel_cpu.eval()\n\nfor text in samples:\n    inputs = tokenizer(text, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n\n    with torch.no_grad():\n        logits = model_cpu(**inputs).logits\n        probs = torch.softmax(logits, dim=1)[0]\n        pred = logits.argmax(dim=1).item()\n\n    print(f\"{label_map[pred]:>8s} ({probs[pred]:.2%})  |  {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}